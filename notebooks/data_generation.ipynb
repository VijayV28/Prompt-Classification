{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "import json\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Defining the data structures and the parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base data structure\n",
    "class PromptObject(BaseModel):\n",
    "    prompt: str = Field(description=\"prompt provided by the user\")\n",
    "    cluster: str = Field(description=\"Cluster to which the prompt belongs to\")\n",
    "    sub_classification: str = Field(\n",
    "        description=\"Sub classification of the prompt within the cluster\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Data structure storing the objects\n",
    "class PromptObjectList(BaseModel):\n",
    "    prompt_objects: List[PromptObject] = Field(\n",
    "        description=\"List of PromptObject objects\"\n",
    "    )\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=PromptObjectList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Generate a total of 15 prompts after considering the following information:\n",
    "\n",
    "Prompt topic: {topic}\n",
    "Prompt sub-topic: {sub_topic}\n",
    "\n",
    "Each prompt should be unique and should be related to the topic and sub-topic provided. The prompt should be realistic and should resemble an actual user's prompt.\n",
    "\n",
    "Make sure you generate 15 different prompts and that none of them are identical. Please \n",
    "follow the instructions given below on how the output should be structured:\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"topic\", \"sub_topic\"],\n",
    "    template=template,\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['sub_topic', 'topic'] partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"prompt_objects\": {\"title\": \"Prompt Objects\", \"description\": \"List of PromptObject objects\", \"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/PromptObject\"}}}, \"required\": [\"prompt_objects\"], \"definitions\": {\"PromptObject\": {\"title\": \"PromptObject\", \"type\": \"object\", \"properties\": {\"prompt\": {\"title\": \"Prompt\", \"description\": \"prompt provided by the user\", \"type\": \"string\"}, \"cluster\": {\"title\": \"Cluster\", \"description\": \"Cluster to which the prompt belongs to\", \"type\": \"string\"}, \"sub_classification\": {\"title\": \"Sub Classification\", \"description\": \"Sub classification of the prompt within the cluster\", \"type\": \"string\"}}, \"required\": [\"prompt\", \"cluster\", \"sub_classification\"]}}}\\n```'} template=\"\\nGenerate a total of 15 prompts after considering the following information:\\n\\nPrompt topic: {topic}\\nPrompt sub-topic: {sub_topic}\\n\\nEach prompt should be unique and should be related to the topic and sub-topic provided. The prompt should be realistic and should resemble an actual user's prompt.\\n\\nMake sure you generate 15 different prompts and that none of them are identical. Please \\nfollow the instructions given below on how the output should be structured:\\n\\n{format_instructions}\\n\\n\"\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - Initialzing the LLM and Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.4)\n",
    "\n",
    "chain = prompt_template | llm | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 - Testing the Prompt Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Business and Productivity\"\n",
    "sub_topic = \"Email Generation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"topic\": topic, \"sub_topic\": sub_topic})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PromptObject(prompt=\"Can you help me draft a follow-up email to a client who hasn't responded to my last message about our proposal?\", cluster='Business and Productivity', sub_classification='Email Generation'),\n",
       " PromptObject(prompt='I need to write a professional email to my team announcing the changes in our project deadlines. What should I include?', cluster='Business and Productivity', sub_classification='Email Generation'),\n",
       " PromptObject(prompt='What is the best way to compose a thank-you email to a colleague who helped me with a recent project?', cluster='Business and Productivity', sub_classification='Email Generation')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.prompt_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Failed to parse PromptObjectList from completion [{\"prompt\": \"Can you help me draft a follow-up email to a client who hasn't responded to my last message regarding the project proposal?\", \"cluster\": \"Client Communication\", \"sub_classification\": \"Follow-up Emails\"}, {\"prompt\": \"I need to write a thank-you email to my team for their hard work on the recent project. Can you suggest a positive and motivating tone?\", \"cluster\": \"Team Management\", \"sub_classification\": \"Appreciation Emails\"}, {\"prompt\": \"What should I include in an introductory email to potential partners for a new business venture? I want to make a strong first impression.\", \"cluster\": \"Networking\", \"sub_classification\": \"Introductory Emails\"}]. Got: 1 validation error for PromptObjectList\n",
      "__root__\n",
      "  PromptObjectList expected dict not list (type=type_error)\n"
     ]
    }
   ],
   "source": [
    "# Invoke the chain and print raw output\n",
    "try:\n",
    "    raw_output = chain.invoke({\"topic\": topic, \"sub_topic\": sub_topic})\n",
    "    print(\"Raw Output:\", raw_output)\n",
    "\n",
    "    # Store result in a variable\n",
    "    result = chain.invoke({\"topic\": topic, \"sub_topic\": sub_topic})\n",
    "    print(\"Parsed Result:\", result)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6 - Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prompts for Communication - Chatbots and Virtual Assistants\n",
      "Generating prompts for Communication - Conversation\n",
      "Generating prompts for Communication - Mental Health\n",
      "Generating prompts for Music and Audio - Music Creation\n",
      "Generating prompts for Music and Audio - Speech Generation\n",
      "Generating prompts for Music and Audio - Podcast Content Creation\n",
      "Generating prompts for Programming and Development - Coding and Programming Assistance\n",
      "Generating prompts for Programming and Development - APi Integration\n",
      "Generating prompts for Business and Productivity - Presentation Creation\n",
      "Generating prompts for Business and Productivity - Email Generation\n"
     ]
    }
   ],
   "source": [
    "clusters = [\n",
    "    \"Communication\",\n",
    "    \"Music and Audio\",\n",
    "    \"Programming and Development\",\n",
    "    \"Business and Productivity\",\n",
    "]\n",
    "\n",
    "sub_classifications = [\n",
    "    [\"Chatbots and Virtual Assistants\", \"Conversation\", \"Mental Health\"],\n",
    "    [\"Music Creation\", \"Speech Generation\", \"Podcast Content Creation\"],\n",
    "    [\"Coding and Programming Assistance\", \"APi Integration\"],\n",
    "    [\"Presentation Creation\", \"Email Generation\"],\n",
    "]\n",
    "\n",
    "for cluster_index in range(len(clusters)):\n",
    "    cluster = clusters[cluster_index]\n",
    "    sub_classes = sub_classifications[cluster_index]\n",
    "    for sub_class in sub_classes:\n",
    "        print(f\"Generating prompts for {cluster} - {sub_class}\")\n",
    "        try:\n",
    "            prompts = chain.invoke({\"topic\": cluster, \"sub_topic\": sub_class})\n",
    "\n",
    "            # Store result in a variable\n",
    "            result = chain.invoke(\n",
    "                {\n",
    "                    \"topic\": clusters[cluster],\n",
    "                    \"sub_topic\": sub_classifications[cluster][sub_class],\n",
    "                }\n",
    "            )\n",
    "            print(\"Parsed Result:\", result)\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-data-analyst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

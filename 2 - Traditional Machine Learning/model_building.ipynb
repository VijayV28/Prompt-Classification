{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Importing necessary libraries and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download(\"punkt\")\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>cluster</th>\n",
       "      <th>sub_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I integrate a chatbot into my website ...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>Chatbots and Virtual Assistants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the best practices for designing a co...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>Chatbots and Virtual Assistants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can chatbots handle complex queries, or are th...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>Chatbots and Virtual Assistants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What platforms are available for building cust...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>Chatbots and Virtual Assistants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I ensure my chatbot understands user in...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>Chatbots and Virtual Assistants</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt        cluster  \\\n",
       "0  How can I integrate a chatbot into my website ...  Communication   \n",
       "1  What are the best practices for designing a co...  Communication   \n",
       "2  Can chatbots handle complex queries, or are th...  Communication   \n",
       "3  What platforms are available for building cust...  Communication   \n",
       "4  How do I ensure my chatbot understands user in...  Communication   \n",
       "\n",
       "                         sub_class  \n",
       "0  Chatbots and Virtual Assistants  \n",
       "1  Chatbots and Virtual Assistants  \n",
       "2  Chatbots and Virtual Assistants  \n",
       "3  Chatbots and Virtual Assistants  \n",
       "4  Chatbots and Virtual Assistants  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/raw/prompts_v1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    # Removing punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "    # Tokenizing text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Removing stopwords and applying lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Joining tokens back to string\n",
    "    processed_text = \" \".join(tokens)\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>cluster</th>\n",
       "      <th>sub_class</th>\n",
       "      <th>processed_prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I integrate a chatbot into my website ...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>Chatbots and Virtual Assistants</td>\n",
       "      <td>integrate chatbot website customer support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the best practices for designing a co...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>Chatbots and Virtual Assistants</td>\n",
       "      <td>best practice designing conversational flow vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can chatbots handle complex queries, or are th...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>Chatbots and Virtual Assistants</td>\n",
       "      <td>chatbots handle complex query better simple task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What platforms are available for building cust...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>Chatbots and Virtual Assistants</td>\n",
       "      <td>platform available building custom chatbots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I ensure my chatbot understands user in...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>Chatbots and Virtual Assistants</td>\n",
       "      <td>ensure chatbot understands user intent accurately</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt        cluster  \\\n",
       "0  How can I integrate a chatbot into my website ...  Communication   \n",
       "1  What are the best practices for designing a co...  Communication   \n",
       "2  Can chatbots handle complex queries, or are th...  Communication   \n",
       "3  What platforms are available for building cust...  Communication   \n",
       "4  How do I ensure my chatbot understands user in...  Communication   \n",
       "\n",
       "                         sub_class  \\\n",
       "0  Chatbots and Virtual Assistants   \n",
       "1  Chatbots and Virtual Assistants   \n",
       "2  Chatbots and Virtual Assistants   \n",
       "3  Chatbots and Virtual Assistants   \n",
       "4  Chatbots and Virtual Assistants   \n",
       "\n",
       "                                    processed_prompt  \n",
       "0         integrate chatbot website customer support  \n",
       "1  best practice designing conversational flow vi...  \n",
       "2   chatbots handle complex query better simple task  \n",
       "3        platform available building custom chatbots  \n",
       "4  ensure chatbot understands user intent accurately  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"processed_prompt\"] = df[\"prompt\"].apply(preprocess_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_cluster = LabelEncoder()\n",
    "le_sub_class = LabelEncoder()\n",
    "\n",
    "df[\"cluster_encoded\"] = le_cluster.fit_transform(df[\"cluster\"])\n",
    "df[\"sub_class_encoded\"] = le_sub_class.fit_transform(df[\"sub_class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(df[\"processed_prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cluster = df[\"cluster_encoded\"]\n",
    "y_sub_class = df[\"sub_class_encoded\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy: 0.96875, F1 Score: 0.9678485576923076\n",
      "Confusion Matrix:\n",
      " [[13  0  0  0]\n",
      " [ 0 19  0  0]\n",
      " [ 0  0 19  0]\n",
      " [ 0  1  1 11]]\n",
      "\n",
      "SVM - Accuracy: 0.953125, F1 Score: 0.9510495052954291\n",
      "Confusion Matrix:\n",
      " [[13  0  0  0]\n",
      " [ 0 19  0  0]\n",
      " [ 0  0 19  0]\n",
      " [ 0  1  2 10]]\n",
      "\n",
      "Naive Bayes - Accuracy: 0.9375, F1 Score: 0.9376003556910568\n",
      "Confusion Matrix:\n",
      " [[11  1  1  0]\n",
      " [ 0 19  0  0]\n",
      " [ 0  1 18  0]\n",
      " [ 0  1  0 12]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_cluster, test_size=0.2, stratify=y_cluster\n",
    ")\n",
    "\n",
    "# Define models to evaluate\n",
    "cluster_models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_acc = 0\n",
    "\n",
    "for name, model in cluster_models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    if accuracy_score(y_test, y_pred) > best_acc:\n",
    "        best_acc = accuracy_score(y_test, y_pred)\n",
    "        best_model = model\n",
    "    print(\n",
    "        f\"{name} - Accuracy: {accuracy_score(y_test, y_pred)}, F1 Score: {f1_score(y_test, y_pred, average='weighted')}\"\n",
    "    )\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(y_test, y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(), 0.96875)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/ML Models/cluster_LR_model.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_model, \"../models/ML Models/cluster_LR_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy: 0.984375, F1 Score: 0.9842948717948719\n",
      "Confusion Matrix:\n",
      " [[6 0 0 0 0 0 0 0 0 0]\n",
      " [0 6 0 1 0 0 0 0 0 0]\n",
      " [0 0 6 0 0 0 0 0 0 0]\n",
      " [0 0 0 7 0 0 0 0 0 0]\n",
      " [0 0 0 0 7 0 0 0 0 0]\n",
      " [0 0 0 0 0 6 0 0 0 0]\n",
      " [0 0 0 0 0 0 6 0 0 0]\n",
      " [0 0 0 0 0 0 0 7 0 0]\n",
      " [0 0 0 0 0 0 0 0 6 0]\n",
      " [0 0 0 0 0 0 0 0 0 6]]\n",
      "\n",
      "SVM - Accuracy: 0.953125, F1 Score: 0.9539658258408258\n",
      "Confusion Matrix:\n",
      " [[6 0 0 0 0 0 0 0 0 0]\n",
      " [0 6 0 1 0 0 0 0 0 0]\n",
      " [0 0 6 0 0 0 0 0 0 0]\n",
      " [0 0 0 7 0 0 0 0 0 0]\n",
      " [0 0 0 0 7 0 0 0 0 0]\n",
      " [0 0 1 0 0 5 0 0 0 0]\n",
      " [0 0 0 0 0 0 6 0 0 0]\n",
      " [0 0 1 0 0 0 0 6 0 0]\n",
      " [0 0 0 0 0 0 0 0 6 0]\n",
      " [0 0 0 0 0 0 0 0 0 6]]\n",
      "\n",
      "Naive Bayes - Accuracy: 0.921875, F1 Score: 0.9113782051282051\n",
      "Confusion Matrix:\n",
      " [[6 0 0 0 0 0 0 0 0 0]\n",
      " [0 6 0 1 0 0 0 0 0 0]\n",
      " [3 0 2 0 1 0 0 0 0 0]\n",
      " [0 0 0 7 0 0 0 0 0 0]\n",
      " [0 0 0 0 7 0 0 0 0 0]\n",
      " [0 0 0 0 0 6 0 0 0 0]\n",
      " [0 0 0 0 0 0 6 0 0 0]\n",
      " [0 0 0 0 0 0 0 7 0 0]\n",
      " [0 0 0 0 0 0 0 0 6 0]\n",
      " [0 0 0 0 0 0 0 0 0 6]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_sub_class, test_size=0.2, stratify=y_sub_class\n",
    ")\n",
    "\n",
    "# Define models to evaluate\n",
    "subclass_models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_acc = 0\n",
    "\n",
    "for name, model in cluster_models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    if accuracy_score(y_test, y_pred) > best_acc:\n",
    "        best_acc = accuracy_score(y_test, y_pred)\n",
    "        best_model = model\n",
    "    print(\n",
    "        f\"{name} - Accuracy: {accuracy_score(y_test, y_pred)}, F1 Score: {f1_score(y_test, y_pred, average='weighted')}\"\n",
    "    )\n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix(y_test, y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(), 0.984375)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/ML Models/subclass_LR_model.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_model, \"../models/ML Models/subclass_LR_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the vectorizer and label encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/ML Models/tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vectorizer, \"../models/ML Models/tfidf_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/ML Models/subclass_label_encoder.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(le_cluster, \"../models/ML Models/cluster_label_encoder.pkl\")\n",
    "joblib.dump(le_sub_class, \"../models/ML Models/subclass_label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Evaluating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_LR = joblib.load(\"../models/ML Models/cluster_LR_model.pkl\")\n",
    "subclass_LR = joblib.load(\"../models/ML Models/subclass_LR_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cluster_and_subclass(new_prompt):\n",
    "\n",
    "    processed_prompt = preprocess_text(new_prompt)\n",
    "    X_new = vectorizer.transform([processed_prompt])\n",
    "\n",
    "    predicted_cluster = cluster_LR.predict(X_new)\n",
    "    predicted_sub_class = subclass_LR.predict(X_new)\n",
    "\n",
    "    # Convert the predicted cluster from its numerical label back to the original string label\n",
    "    predicted_cluster_label = le_cluster.inverse_transform(predicted_cluster)\n",
    "    predicted_sub_class_label = le_sub_class.inverse_transform(predicted_sub_class)\n",
    "\n",
    "    return predicted_cluster_label[0], predicted_sub_class_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Programming and Development', 'API Integration')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_cluster_and_subclass(\"How to use OpenAI's API within Streamlit?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing the confidence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vector = joblib.load(\"../models/ML Models/tfidf_vectorizer.pkl\")\n",
    "cluster_encoder = joblib.load(\"../models/ML Models/cluster_label_encoder.pkl\")\n",
    "subclass_encoder = joblib.load(\"../models/ML Models/subclass_label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cluster_and_subclass(new_prompt):\n",
    "    # Preprocess the new prompt\n",
    "    processed_prompt = preprocess_text(new_prompt)\n",
    "\n",
    "    # Transform the processed prompt using the loaded vectorizer\n",
    "    X_new = loaded_vector.transform([processed_prompt])\n",
    "\n",
    "    # Predict the cluster\n",
    "    cluster_probabilities = cluster_LR.predict_proba(X_new)\n",
    "    subclass_probabilities = subclass_LR.predict_proba(X_new)\n",
    "\n",
    "    # Get the index of the highest probability (the predicted class)\n",
    "    cluster_predicted_index = cluster_probabilities.argmax(axis=1)\n",
    "    subclass_predicted_index = subclass_probabilities.argmax(axis=1)\n",
    "\n",
    "    # Get the confidence score (highest probability)\n",
    "    cluster_confidence_score = cluster_probabilities[0][cluster_predicted_index]\n",
    "    subclass_confidence_score = subclass_probabilities[0][subclass_predicted_index]\n",
    "\n",
    "    # Convert the predicted cluster from its numerical label back to the original string label\n",
    "    predicted_cluster_label = cluster_encoder.inverse_transform(cluster_predicted_index)\n",
    "    predicted_subclass_label = subclass_encoder.inverse_transform(\n",
    "        subclass_predicted_index\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        predicted_cluster_label[0],\n",
    "        cluster_confidence_score,\n",
    "        predicted_subclass_label[0],\n",
    "        subclass_confidence_score,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Music and Audio', array([0.36561371]), 'Music Creation', array([0.16015151]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_cluster_and_subclass(\"What is digital marketing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Music and Audio',\n",
       " array([0.31907863]),\n",
       " 'Coding and Programming Assistance',\n",
       " array([0.12500426]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_cluster_and_subclass(\"How to cook a pizza?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Communication', array([0.79150815]), 'Mental Health', array([0.64666375]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_cluster_and_subclass(\"What can I do to improve my mental health?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Business and Productivity',\n",
       " array([0.29935747]),\n",
       " 'Presentation Creation',\n",
       " array([0.2522915]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_cluster_and_subclass(\"What can I do to improve my business?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-data-analyst",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
